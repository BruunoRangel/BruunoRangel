{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bruno_Rangel",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BruunoRangel/BruunoRangel/blob/main/Bruno_Rangel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Coloque* seu nome"
      ],
      "metadata": {
        "id": "EjjkifA3S8P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Meu nome é: Bruno Rangel Balbino dos Santos')"
      ],
      "metadata": {
        "id": "-5KKGR3vS9_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercícios de Processamento de Dados##\n",
        "Nesta parte pode-se usar as bibliotecas nativas do python como a collections, re e random. Também pode-se usar o NumPy."
      ],
      "metadata": {
        "id": "V95d4R2DTMiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 1.1##\n",
        "Crie um dicionário com os k itens mais frequentes de uma lista.\n",
        "\n",
        "Por exemplo, dada a lista de itens L=['a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a'] e k=2, o resultado deve ser um dicionário cuja chave é o item e o valor é a sua frequência: {'a': 4, 'e': 3}"
      ],
      "metadata": {
        "id": "qJLMmVqBTUKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k(L, k):\n",
        "    # Escreva aqui o código\n",
        "    from collections import Counter\n",
        "    c = dict(list((Counter(L).most_common(k)))) \n",
        "    return c"
      ],
      "metadata": {
        "id": "6KZ1wR83TfAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação está correta usando uma entrada com poucos itens:"
      ],
      "metadata": {
        "id": "FBosHWjYTmeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L = ['f', 'a', 'a', 'd', 'b', 'd', 'c', 'e', 'a', 'b', 'e', 'e', 'a', 'd']\n",
        "k = 3\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "metadata": {
        "id": "-Ifh0faJTpAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f552feb0-31e4-47b1-e1a5-2bb75892d9ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'a': 4, 'd': 3, 'e': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente usando uma entrada com 10M de itens:\n",
        "\n",
        "> Bloco com recuo\n",
        "\n"
      ],
      "metadata": {
        "id": "Gp0W1rVRTsWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "L = random.choices('abcdefghijklmnopqrstuvwxyz', k=10_000_000)\n",
        "k = 10000\n"
      ],
      "metadata": {
        "id": "lGcY3-KsTs_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "resultado = top_k(L=L, k=k)\n",
        "print(f'resultado: {resultado}')"
      ],
      "metadata": {
        "id": "0Fetdh68TvSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6436ee5-7b84-46a1-98ed-67709255f1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "resultado: {'g': 385714, 'b': 385664, 'v': 385629, 'm': 385509, 's': 385199, 'q': 385179, 'p': 385130, 'n': 385020, 'a': 384911, 'u': 384847, 'h': 384825, 'i': 384822, 'e': 384799, 'k': 384735, 'f': 384620, 'y': 384561, 'z': 384456, 'r': 384442, 'c': 384198, 'd': 384163, 'j': 383988, 't': 383936, 'x': 383670, 'l': 383625, 'w': 383425, 'o': 382933}\n",
            "1 loop, best of 5: 543 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 1.2\n",
        "Em processamento de linguagem natural, é comum convertemos as palavras de um texto para uma lista de identificadores dessas palavras. Dado o dicionário V abaixo onde as chaves são palavras e os valores são seus respectivos identificadores, converta o texto D para uma lista de identificadores.\n",
        "\n",
        "Palavras que não existem no dicionário deverão ser convertidas para o identificador do token unknown.\n",
        "\n",
        "O código deve ser insensível a maiúsculas (case-insensitive).\n",
        "\n",
        "Se atente que pontuações (vírgulas, ponto final, etc) também são consideradas palavras."
      ],
      "metadata": {
        "id": "yoZLNvK3UGM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokens_to_ids(text, vocabulary):\n",
        "    # escreva o código aqui. \n",
        "    txt = re.findall(r\"\\w+|[^\\w\\s]\", D.lower())  \n",
        "    V1 = set(vocabulary)\n",
        "    ind = []\n",
        "    for i in txt:\n",
        "      i1 = set([i])\n",
        "      if i1.issubset(V1) == True:\n",
        "        ind.append(vocabulary[str(i)])\n",
        "      else:\n",
        "        ind.append(vocabulary[\"unknown\"])\n",
        "    return ind"
      ],
      "metadata": {
        "id": "6V0R7myuUJx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[texto do link](https://)Mostre que sua implementação esta correta com um exemplo pequeno:"
      ],
      "metadata": {
        "id": "9LPDubnyUM26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  import re\n",
        "  V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "  D = 'Eu gosto de comer pizza.'\n",
        "  print(\"Lista de indificadores =\",str(tokens_to_ids(D, V)))"
      ],
      "metadata": {
        "id": "89sejHzcUPlP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925772f3-dc16-4f2d-cfa7-7968a466df85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lista de indificadores = [1, 3, 2, 4, -1, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BiwrERuYUU6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "V = {'eu': 1, 'de': 2, 'gosto': 3, 'comer': 4, '.': 5, 'unknown': -1}\n",
        "D = ' '.join(1_000_000 * (['Eu gosto de comer pizza.']))"
      ],
      "metadata": {
        "id": "BIMRDpwTUmqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "resultado = tokens_to_ids(D, V)"
      ],
      "metadata": {
        "id": "CQfG5agoUoY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4917bb57-790c-4195-837e-bd26f541e996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 5.31 s per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 1.3\n",
        "\n",
        "Em aprendizado profundo é comum termos que lidar com arquivos muito grandes.\n",
        "\n",
        "Dado um arquivo de texto onde cada item é separado por `\\n`, escreva um programa que amostre `k` itens desse arquivo aleatoriamente.\n",
        "\n",
        "Nota 1: Assuma amostragem de uma distribuição uniforme, ou seja, todos os itens tem a mesma probablidade de amostragem.\n",
        "\n",
        "Nota 2: Assuma que o arquivo não cabe em memória.\n",
        "\n",
        "Nota 3: Utilize apenas bibliotecas nativas do python."
      ],
      "metadata": {
        "id": "HyeKvysIUqKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(path: str, k: int):\n",
        "    # Escreva o seu código aqui.\n",
        "    arq = open(path)\n",
        "    linhas = arq.readlines()\n",
        "    l = (np.random.rand((n_samples)) * total_size).astype(np.int)\n",
        "    amostras = []\n",
        "    for i in l:\n",
        "      amostras.append(linhas[i])  \n",
        "\n",
        "    return amostras"
      ],
      "metadata": {
        "id": "JcZKqx2vU0ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação está correta com um exemplo pequeno:"
      ],
      "metadata": {
        "id": "Jk6QNNkBU9_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "filename = 'small.txt'\n",
        "total_size = 100\n",
        "n_samples = 10\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))\n",
        "\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "print(samples)\n",
        "print(len(samples) == n_samples)"
      ],
      "metadata": {
        "id": "Gf0cTqWPU_pf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a230066-d0a3-4f43-cba0-bfa8e7f685d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['line 15\\n', 'line 72\\n', 'line 28\\n', 'line 40\\n', 'line 76\\n', 'line 38\\n', 'line 43\\n', 'line 36\\n', 'line 52\\n', 'line 50\\n']\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente com um exemplo grande:"
      ],
      "metadata": {
        "id": "2-mqa5IHVp35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'large.txt'\n",
        "total_size = 1_000_000\n",
        "n_samples = 10000\n",
        "\n",
        "with open(filename, 'w') as fout:\n",
        "    fout.write('\\n'.join(f'line {i}' for i in range(total_size)))"
      ],
      "metadata": {
        "id": "C8y_WatsVuZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "samples = sample(path=filename, k=n_samples)\n",
        "assert len(samples) == n_samples"
      ],
      "metadata": {
        "id": "2ndvOCSYVwkd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc17e2c7-dc9f-4451-a415-55c81d05c537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 84.4 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parte 2:\n",
        "Exercícios de Numpy\n",
        "Nesta parte deve-se usar apenas a biblioteca NumPy. Aqui não se pode usar o PyTorch."
      ],
      "metadata": {
        "id": "lBckt7PZVzcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 2.1\n",
        "\n",
        "Quantos operações de ponto flutuante (flops) de soma e de multiplicação tem a multiplicação matricial $AB$, sendo que a matriz $A$ tem tamanho $m \\times n$ e a matriz $B$ tem tamanho $n \\times p$?"
      ],
      "metadata": {
        "id": "aeIrt7ipV2ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resposta:\n",
        "- número de somas: sendo m número de linhas n o número de colunas de A \n",
        "e n o número de linhas e p o número de colunas de B a quntidade total de somas será: $m \\times (n$-1) $\\times p$\n",
        "- número de multiplicações: com as mesmas considerações para soma a quantidade de multiplicações: $m \\times n$ $\\times p$"
      ],
      "metadata": {
        "id": "scVzeAuoV9Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2.2\n",
        "Em programação matricial, não se faz o loop em cada elemento da matriz, mas sim, utiliza-se operações matriciais.\n",
        "\n",
        "Dada a matriz A abaixo, calcule a média dos valores de cada linha sem utilizar laços explícitos.\n",
        "\n",
        "Utilize apenas a biblioteca numpy."
      ],
      "metadata": {
        "id": "IuEyIU4uWQfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "rYC36-qDWStR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.arange(24).reshape(4, 6)\n",
        "print(A)"
      ],
      "metadata": {
        "id": "sLaATzxCWUOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0984ef-836d-4433-8ccc-1d5453fc5328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = np.mean(A,axis=1)\n",
        "print(media)"
      ],
      "metadata": {
        "id": "DVBUuWlLWWHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4c6da5-9873-401b-87ab-1568ec7907ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.5  8.5 14.5 20.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2.3\n",
        "\n",
        "Seja a matriz $C$ que é a normalização da matriz $A$:\n",
        "$$ C(i,j) = \\frac{A(i,j) - A_{min}}{A_{max} - A_{min}} $$\n",
        "\n",
        "Normalizar a matriz `A` do exercício acima de forma que seus valores fiquem entre 0 e 1."
      ],
      "metadata": {
        "id": "lGCy20hWWdIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = (A - A.min())/(A.max() - A.min())\n",
        "print(C) \n"
      ],
      "metadata": {
        "id": "dQZXLIrxWrzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35179d9e-d800-48e3-8d2f-50d2235a529d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.04347826 0.08695652 0.13043478 0.17391304 0.2173913 ]\n",
            " [0.26086957 0.30434783 0.34782609 0.39130435 0.43478261 0.47826087]\n",
            " [0.52173913 0.56521739 0.60869565 0.65217391 0.69565217 0.73913043]\n",
            " [0.7826087  0.82608696 0.86956522 0.91304348 0.95652174 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2.4\n",
        "Modificar o exercício anterior de forma que os valores de cada coluna da matriz A sejam normalizados entre 0 e 1 independentemente dos valores das outras colunas."
      ],
      "metadata": {
        "id": "-vP5Q8D0WtvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = (A - np.min(A,axis=0))/np.ptp(A,axis=0)\n",
        "print(C)"
      ],
      "metadata": {
        "id": "EKNqJ87DWwR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b8a9c2-661f-4cd5-fdfe-99380caa8d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.         0.        ]\n",
            " [0.33333333 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333]\n",
            " [0.66666667 0.66666667 0.66666667 0.66666667 0.66666667 0.66666667]\n",
            " [1.         1.         1.         1.         1.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2.5\n",
        "Modificar o exercício anterior de forma que os valores de cada linha da matriz A sejam normalizados entre 0 e 1 independentemente dos valores das outras linhas."
      ],
      "metadata": {
        "id": "clqA4S6AWyoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreva sua solução aqui.\n",
        "C = (A - np.reshape(np.min(A,axis=1),(4,1)))/np.reshape(np.ptp(A,axis=1),(4,1))\n",
        "print(C)"
      ],
      "metadata": {
        "id": "95oEAQdfW2Km",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64b851f-a0de-4ffa-eb81-2740d12adc4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]\n",
            " [0.  0.2 0.4 0.6 0.8 1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2.6\n",
        "A função softmax é bastante usada em apredizado de máquina para converter uma lista de números para uma distribuição de probabilidade, isto é, os números ficarão normalizados entre zero e um e sua soma será igual à um.\n",
        "\n",
        "Implemente a função softmax com suporte para batches, ou seja, o softmax deve ser aplicado a cada linha da matriz. Deve-se usar apenas a biblioteca numpy. Se atente que a exponenciação gera estouro de representação quando os números da entrada são muito grandes. Tente corrigir isto."
      ],
      "metadata": {
        "id": "8bXxog0NW9kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def softmax(A):\n",
        "    '''\n",
        "    Aplica a função de softmax à matriz `A`.\n",
        "\n",
        "    Entrada:\n",
        "      `A` é uma matriz M x N, onde M é o número de exemplos a serem processados\n",
        "      independentemente e N é o tamanho de cada exemplo.\n",
        "    \n",
        "    Saída:\n",
        "      Uma matriz M x N, onde a soma de cada linha é igual a um.\n",
        "    '''\n",
        "    # Escreva sua solução aqui.\n",
        "    N = np.log(A  + (np.abs(A.min()) + 1))\n",
        "    A = np.exp(N) / np.reshape(np.sum(np.exp(N),axis=1),(A.shape[0],1))\n",
        "      \n",
        "    return A"
      ],
      "metadata": {
        "id": "nBb8A2T0W_9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação está correta usando uma matriz pequena como \n",
        "\n"
      ],
      "metadata": {
        "id": "tySjklQHXiQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([[0.5, -1, 1000],\n",
        "              [-2,   0, 0.5]])\n",
        "\n",
        "A = softmax(A)\n",
        "print(A)"
      ],
      "metadata": {
        "id": "PzDv-1-vXl0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a23674c-3460-4405-d86f-5b9fa90bf809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0034705  0.00198314 0.99454636]\n",
            " [0.13333333 0.4        0.46666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código a seguir verifica se sua implementação do softmax está correta.\n",
        "\n",
        "A soma de cada linha de A deve ser 1;\n",
        "Os valores devem estar entre 0 e 1"
      ],
      "metadata": {
        "id": "Y5azVReNXoAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.allclose(softmax(A).sum(axis=1), 1) and softmax(A).min() >= 0 and softmax(A).max() <= 1"
      ],
      "metadata": {
        "id": "SDD0Mk2zXtVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0329c9fe-b765-4613-d435-a2016ed417fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ],
      "metadata": {
        "id": "pvuycHXuXzvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.uniform(low=-10, high=10, size=(128, 100_000))\n"
      ],
      "metadata": {
        "id": "PXQLPDqeX2rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "softmax(A)"
      ],
      "metadata": {
        "id": "7NJ2Ii4tX4PC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5cab03-9b49-4d90-e726-1fb16bb332bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 831 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SM = softmax(A)\n",
        "np.allclose(SM.sum(axis=1), 1) and SM.min() >= 0 and SM.max() <= 1"
      ],
      "metadata": {
        "id": "-1gjTVxxYTG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127b187d-abba-4037-c3e1-bbebe21c0d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2.7\n",
        "A codificação one-hot é usada para codificar entradas categóricas. É uma codificação onde apenas um bit é 1 e os demais são zero, conforme a tabela a seguir.\n",
        "\n",
        "| Decimal | Binary | One-hot\n",
        "| ------- | ------ | -------\n",
        "| 0 | 000    | 1 0 0 0 0 0 0 0\n",
        "| 1 | 001    | 0 1 0 0 0 0 0 0\n",
        "| 2 | 010    | 0 0 1 0 0 0 0 0\n",
        "| 3 | 011    | 0 0 0 1 0 0 0 0\n",
        "| 4 | 100    | 0 0 0 0 1 0 0 0\n",
        "| 5 | 101    | 0 0 0 0 0 1 0 0\n",
        "| 6 | 110    | 0 0 0 0 0 0 1 0\n",
        "| 7 | 111    | 0 0 0 0 0 0 0 1"
      ],
      "metadata": {
        "id": "8D0enetBYrU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implemente a função one_hot(y, n_classes) que codifique o vetor de inteiros y que possuem valores entre 0 e n_classes-1."
      ],
      "metadata": {
        "id": "ety1VDY3Y3WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(y, n_classes):\n",
        "    # Escreva seu código aqui.\n",
        "    m = np.arange(y.size)\n",
        "    shape = (y.size, N_CLASSES)\n",
        "    one_hot = np.zeros(shape)\n",
        "    one_hot[m, y] = 1\n",
        "    return one_hot\n",
        "    "
      ],
      "metadata": {
        "id": "s0vie4QLY72d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "N_CLASSES = 9\n",
        "N_SAMPLES = 10\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(one_hot(y, N_CLASSES))"
      ],
      "metadata": {
        "id": "oj0fPakOY-Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040890b5-78ef-4cc5-b80e-8a267248e6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que sua implementação é eficiente usando uma matriz grande como entrada:"
      ],
      "metadata": {
        "id": "WLRsklQJZC5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_SAMPLES = 100_000\n",
        "N_CLASSES = 1_000\n",
        "y = (np.random.rand((N_SAMPLES)) * N_CLASSES).astype(np.int)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "lwSGQckGZGky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848b1daf-3545-457b-bbce-5016f0949caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[311 986 594 ...  72  16 882]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "one_hot(y, N_CLASSES)\n"
      ],
      "metadata": {
        "id": "nlei7EydZIli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0deab6-cad3-4009-835d-51ee7648cb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 192 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = one_hot(y, N_CLASSES)\n",
        "print(x[0,:])"
      ],
      "metadata": {
        "id": "-VfS1ccIwUop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fa412b-4c85-4934-f837-f8127455daba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercício 2.8\n",
        "\n",
        "Implemente uma classe que normalize um array de pontos flutuantes `array_a` para a mesma média e desvio padrão de um outro array `array_b`, conforme exemplo abaixo:\n",
        "```\n",
        "array_a = np.array([-1, 1.5, 0])\n",
        "array_b = np.array([1.4, 0.8, 0.3, 2.5])\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize(array_a)\n",
        "print(normalized_array)  # Deve imprimir [0.3187798  2.31425165 1.11696854]\n",
        "```"
      ],
      "metadata": {
        "id": "QA98TkwKZKkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np "
      ],
      "metadata": {
        "id": "DwvA70IrkzZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escreva seu código aqui.\n",
        "class Normalizer:\n",
        "  def __init__(self, array_b):\n",
        "    self.b = np.array(array_b)\n",
        "    self.mB = np.mean(array_b)\n",
        "    self.sB = np.std(array_b)\n",
        "    self.scoreb = (array_b - self.mB) / self.sB\n",
        "  \n",
        "  def N(self,array_a):\n",
        "    self.a = np.array(array_a)\n",
        "    self.mA = np.mean(array_a)\n",
        "    self.sA = np.std(array_a)\n",
        "    return self.mB + (self.a - self.mA) * (self.sB/self.sA)"
      ],
      "metadata": {
        "id": "8jp3r3YdZQ4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostre que seu código está correto com o exemplo abaixo:"
      ],
      "metadata": {
        "id": "-pfjwinNmPa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_a = [-1, 1.5, 0]\n",
        "array_b = [1.4, 0.8, 0.3, 2.5]\n",
        "normalize = Normalizer(array_b)\n",
        "normalized_array = normalize.N(array_a)\n",
        "print(normalized_array)"
      ],
      "metadata": {
        "id": "HAOpS7FdZbXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff670ca-e359-4efb-b066-c14df8e37d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3187798  2.31425165 1.11696854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 3:\n",
        "\n",
        "##Exercícios Pytorch: Grafo Computacional e Gradientes\n",
        "\n",
        "Nesta parte pode-se usar quaisquer bibliotecas."
      ],
      "metadata": {
        "id": "0z0K9GSCZdXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um dos principais fundamentos para que o PyTorch seja adequado para deep learning é a sua habilidade de calcular o gradiente automaticamente a partir da expressões definidas. Essa facilidade é implementada através do cálculo automático do gradiente e construção dinâmica do grafo computacional."
      ],
      "metadata": {
        "id": "W5-pgzUsZgg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grafo computacional\n",
        "\n",
        "Seja um exemplo simples de uma função de perda J dada pela Soma dos Erros ao Quadrado (SEQ - Sum of Squared Errors): \n",
        "$$ J = \\sum_i (x_i w - y_i)^2 $$\n",
        "que pode ser reescrita como:\n",
        "$$ \\hat{y_i} = x_i w $$\n",
        "$$ e_i = \\hat{y_i} - y_i $$\n",
        "$$ e2_i = e_i^2 $$\n",
        "$$ J = \\sum_i e2_i $$\n",
        "\n",
        "As redes neurais são treinadas através da minimização de uma função de perda usando o método do gradiente descendente. Para ajustar o parâmetro $w$ precisamos calcular o gradiente $  \\frac{ \\partial J}{\\partial w} $. Usando a\n",
        "regra da cadeia podemos escrever:\n",
        "$$ \\frac{ \\partial J}{\\partial w} = \\frac{ \\partial J}{\\partial e2_i} \\frac{ \\partial e2_i}{\\partial e_i} \\frac{ \\partial e_i}{\\partial \\hat{y_i} } \\frac{ \\partial \\hat{y_i}}{\\partial w}$$ "
      ],
      "metadata": {
        "id": "RoFLk_53ZkTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e**2\n",
        "    J = e2.sum()\n",
        "```"
      ],
      "metadata": {
        "id": "WEJwz0htZpig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As quatro expressões acima, para o cálculo do J podem ser representadas pelo grafo computacional visualizado a seguir: os círculos são as variáveis (tensores), os quadrados são as operações, os números em preto são os cálculos durante a execução das quatro expressões para calcular o J (forward, predict). O cálculo do gradiente, mostrado em vermelho, é calculado pela regra da cadeia, de trás para frente (backward)."
      ],
      "metadata": {
        "id": "ehawjqqYZuQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/robertoalotufo/files/master/figures/GrafoComputacional.png\" width=\"600pt\"/>"
      ],
      "metadata": {
        "id": "uc0DNCtzZyAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "Para entender melhor o funcionamento do grafo computacional com os tensores, recomenda-se leitura em:\n",
        "\n",
        "https://pytorch.org/docs/stable/notes/autograd.html"
      ],
      "metadata": {
        "id": "m4ivz6OOZ1I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Dv1cu0v6Z9d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "id": "nKR8TmPBZ-x-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98015d6f-9779-42d5-9858-c5ee079a8acc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor com atributo .requires_grad=True**\n",
        "\n",
        "Quando um tensor possui o atributo `requires_grad` como verdadeiro, qualquer expressão que utilizar esse tensor irá construir um grafo computacional para permitir posteriormente, após calcular a função a ser derivada, poder usar a regra da cadeia e calcular o gradiente da função em termos dos tensores que possuem o atributo `requires_grad`."
      ],
      "metadata": {
        "id": "sii-L0DZaFbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.arange(0, 8, 2).float()\n",
        "y"
      ],
      "metadata": {
        "id": "C91jvu3taIr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3ee87a-99a0-4a4e-c18b-4df2e8674b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0, 4).float()\n",
        "x"
      ],
      "metadata": {
        "id": "qxBdBgp0aLFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b428ba-a11b-486e-c6cd-b82d3a6bb0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.ones(1, requires_grad=True)\n",
        "w"
      ],
      "metadata": {
        "id": "hAu0ENK7aVpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1a6fc1-dd84-47a6-e806-fbf7bb664283"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cálculo automático do gradiente da função perda J"
      ],
      "metadata": {
        "id": "Zj6DDisGaaNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seja a expressão: $$ J = \\sum_i ((x_i  w) - y_i)^2 $$\n",
        "\n",
        "Queremos calcular a derivada de $J$ em relação a $w$."
      ],
      "metadata": {
        "id": "z4MS5NUAaa45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward pass\n",
        "Durante a execução da expressão, o grafo computacional é criado. Compare os valores de cada parcela calculada com os valores em preto da figura ilustrativa do grafo computacional."
      ],
      "metadata": {
        "id": "tc59u757ae-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict (forward)\n",
        "y_pred = x * w; print('y_pred =', y_pred)\n",
        "\n",
        "# cálculo da perda J: loss\n",
        "e = y_pred - y; print('e =',e)\n",
        "e2 = e.pow(2) ; print('e2 =', e2)\n",
        "J = e2.sum()  ; print('J =', J)"
      ],
      "metadata": {
        "id": "SfD6t3wUaiBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "423b6ee4-20a3-425f-b809-10ffca38554c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_pred = tensor([0., 1., 2., 3.], grad_fn=<MulBackward0>)\n",
            "e = tensor([ 0., -1., -2., -3.], grad_fn=<SubBackward0>)\n",
            "e2 = tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n",
            "J = tensor(14., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# Isto está formatado como código\n",
        "```\n",
        "\n",
        "## Backward pass"
      ],
      "metadata": {
        "id": "vM5W_WJcakNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O `backward()` varre o grafo computacional a partir da variável a ele associada (raiz) e calcula o gradiente para todos os tensores que possuem o atributo `requires_grad` como verdadeiro.\n",
        "Observe que os tensores que tiverem o atributo `requires_grad` serão sempre folhas no grafo computacional.\n",
        "O `backward()` destroi o grafo após sua execução. Esse comportamento é padrão no PyTorch. \n",
        "\n",
        "A título ilustrativo, se quisermos depurar os gradientes dos nós que não são folhas no grafo computacional, precisamos primeiro invocar `retain_grad()` em cada um desses nós, como a seguir. Entretanto nos exemplos reais não há necessidade de verificar o gradiente desses nós."
      ],
      "metadata": {
        "id": "Kxx33xLianYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e2.retain_grad()\n",
        "e.retain_grad()\n",
        "y_pred.retain_grad()"
      ],
      "metadata": {
        "id": "mdBh-OUpawvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E agora calculamos os gradientes com o `backward()`.\n",
        "\n",
        "w.grad é o gradiente de J em relação a w."
      ],
      "metadata": {
        "id": "bKejABZlay8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if w.grad: w.grad.zero_()\n",
        "J.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "id": "rVMPg4Lua1_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13de0601-db56-4ada-8130-c705a2c1f9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-28.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostramos agora os gradientes que estão grafados em vermelho no grafo computacional:"
      ],
      "metadata": {
        "id": "gSmAnZGEa4G3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(e2.grad)\n",
        "print(e.grad)\n",
        "print(y_pred.grad)"
      ],
      "metadata": {
        "id": "vrdCcc1oa59i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c9c1af8-e6fd-4480-b08b-7d0279cfb025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.])\n",
            "tensor([ 0., -2., -4., -6.])\n",
            "tensor([ 0., -2., -4., -6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.1\n",
        "Calcule o mesmo gradiente ilustrado no exemplo anterior usando a regra das diferenças finitas, de acordo com a equação a seguir, utilizando um valor de $\\Delta w$ bem pequeno.\n",
        "\n",
        "$$ \\frac{\\partial J}{\\partial w} = \\frac{J(w + \\Delta w) - J(w - \\Delta w)}{2 \\Delta w} $$"
      ],
      "metadata": {
        "id": "TuUIgbpDa7w0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def J_func(w, x, y):\n",
        "    # programe a função J_func, para facilitar\n",
        "    y_pred = x * w\n",
        "    e = y_pred - y\n",
        "    e2 = e.pow(2)\n",
        "    J = e2.sum()\n",
        "    return J\n",
        "\n",
        "# Calcule o gradiente usando a regra diferenças finitas\n",
        "# Confira com o valor já calculado anteriormente\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "dW = 0.0001  \n",
        "j = J_func\n",
        "\n",
        "grad = (j(w + dW, x, y) - j(w - dW, x, y))/(2*dW)\n",
        "print('grad=', grad)"
      ],
      "metadata": {
        "id": "Zi2o6UR8bAsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd92dfa9-befe-48bb-db17-193ab0fd2d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad= tensor(-27.9999)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.2\n",
        "\n",
        "Minimizando $J$ pelo gradiente descendente\n",
        "\n",
        "$$ w_{k+1} = w_k - \\lambda \\frac {\\partial J}{\\partial w} $$\n",
        "\n",
        "Supondo que valor inicial ($k=0$) $w_0 = 1$, use learning rate $\\lambda = 0.01$ para calcular o valor do novo $w_{20}$, ou seja, fazendo 20 atualizações de gradientes. Deve-se usar a função `J_func` criada no exercício anterior.\n",
        "\n",
        "Confira se o valor do primeiro gradiente está de acordo com os valores já calculado acima"
      ],
      "metadata": {
        "id": "WtrQDSJ8bEh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1)\n",
        "xVet = []\n",
        "yVet = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    yVet.append(i)\n",
        "    J = J_func(w, x, y)\n",
        "    print('J=', J)\n",
        "    xVet.append(J)\n",
        "    grad = (j(w + dW, x, y) - j(w - dW, x, y))/(2*dW)\n",
        "    print('grad =',grad)\n",
        "    w = w - learning_rate* grad\n",
        "    print('w =', w)\n",
        "\n",
        "# Plote o gráfico da loss J pela iteração i\n",
        "plt.plot(xVet,yVet,color=\"blue\")\n",
        "plt.scatter(xVet,yVet,color=\"red\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p502AM-cbHvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41f05977-490e-4467-bc4a-dc8c4a9a7c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = tensor(-27.9999)\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = tensor(-20.1607)\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = tensor(-14.5137)\n",
            "w = tensor([1.6267])\n",
            "i = 3\n",
            "J= tensor(1.9505)\n",
            "grad = tensor(-10.4505)\n",
            "w = tensor([1.7312])\n",
            "i = 4\n",
            "J= tensor(1.0112)\n",
            "grad = tensor(-7.5281)\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5240)\n",
            "grad = tensor(-5.4196)\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2716)\n",
            "grad = tensor(-3.9014)\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1407)\n",
            "grad = tensor(-2.8086)\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0729)\n",
            "grad = tensor(-2.0218)\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0378)\n",
            "grad = tensor(-1.4555)\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = tensor(-1.0472)\n",
            "w = tensor([1.9731])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = tensor(-0.7540)\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = tensor(-0.5432)\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = tensor(-0.3910)\n",
            "w = tensor([1.9900])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = tensor(-0.2814)\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = tensor(-0.2027)\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = tensor(-0.1458)\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = tensor(-0.1051)\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = tensor(-0.0756)\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.2911e-05)\n",
            "grad = tensor(-0.0544)\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RcZf3v8fc3SW9peqU0vdG0tIggCDQV8FYaLrXt4YjHhVx+OQUUraiAekBFq9WD4kJFRFYVrNJT0NiACsqBciklFfCI0EChLVBoofeWlqa3NKWX9Hv+2DvtJJ1JJjNJJnvn81prr5n97L1nPmGV757Zs5/nMXdHRETiKy/XAUREpH2p0IuIxJwKvYhIzKnQi4jEnAq9iEjMFeQ6QDKDBg3yUaNGZXTsnj176N27d9sGaidRygrRyhulrBCtvFHKCtHKm03W6urq99z92KQb3b3TLaWlpZ6pqqqqjI/taFHK6h6tvFHK6h6tvFHK6h6tvNlkBRZ7ipqqSzciIjGnQi8iEnMq9CIiMadCLyIScyr0IiIxF59CX1EBo0ZBdXXwWFGR60QiIp1Cp7yPvtUqKmD6dKirC9bXrAnWAcrLc5dLRKQTiMcn+hkzoK6OH/N9XlhRErTV1QXtIiJdXDwK/dq1ANzKTbz0ZslR7SIiXVk8Cv3Ika1rFxHpQuJR6G+5BQoLG7cVFgbtIiJdXDx+jG34wXWaBY8lJUGR1w+xIiIxKfQQFPXpwJBiWLQ612lERDqNeFy6ERGRlFToRURiToVeRCTm4lPoKypgbx1sfldDIIiIJIhHoW8YAsE9WG8YAkHFXkQkJoU+HAKhEQ2BICICxKXQpxrqQEMgiIjEpNBrCAQRkZRaLPRmNsfMtpjZsoS2+81sSbisNrMlKY5dbWZLw/0Wt2XwRjQEgohISun0jJ0LzALua2hw90sbnpvZL4GdzRxf5u7vZRowLRoCQUQkpRYLvbs/Y2ajkm0zMwMuAc5t21gZ0BAIIiJJmTfcktjcTkGhf8TdT2nSPgG43d3HpzjuHWA74MDv3H12M+8xnaBUU1xcXFpZWZnmn3DElCmfZMqU1Vx//bpWH5sLtbW1FBUV5TpG2qKUN0pZIVp5o5QVopU3m6xlZWXVqWox7t7iAowCliVpvwu4oZnjhoePg4FXgAnpvF9paalnorDQ/dJL12R0bC5UVVXlOkKrRClvlLK6RytvlLK6RytvNlmBxZ6ipmZ8142ZFQCfBe5PtY+7bwgftwAPAWdm+n4tUs9YEZGksrm98nzgDXdfn2yjmfU2sz4Nz4FJwLJk+2ZNPWNFRFJK5/bKecC/gRPNbL2ZXR1uugyY12TfYWY2P1wtBp4zs1eAF4BH3f3xtoueQD1jRURSSueum8tTtF+VpG0jMDV8/jZwWpb50pPQA9axpO0iIl1VrHrGGp60XUSkK4tHoVfPWBGRlOIxZ6x6xoqIpBSPQg9BUf8yUKyesSIiieJx6UZERFJSoRcRibn4FPqKCqjbA++qZ6yISKJ4FHr1jBURSSkehV49Y0VEUopHoU/sGevJ20VEuqp4FHr1jBURSSkehV49Y0VEUopHhyn1jBURSSkehR6Con4NQc/Yf67OdRoRkU4jHpduEqQxBa6ISJcSq0Jv1vI+IiJdTawKvYiIHC2dqQTnmNkWM1uW0PYjM9tgZkvCZWqKYyeb2QozW2lmN7Vl8KNUVEDtbtiiIRBERBKl84l+LjA5Sfuv3P30cJnfdKOZ5QO/AaYAJwOXm9nJ2YRNSUMgiIik1GKhd/dngJoMXvtMYKW7v+3u+4FK4KIMXqdliUMgeHihXkMgiIgA2d1eea2ZXQEsBm5w9+1Ntg8H1iWsrwfOSvViZjYdmA5QXFzMokWL0k9y3XUAHPp+D/YXFbHottuObGvN63Sw2tra1v2dORalvFHKCtHKG6WsEK287ZbV3VtcgFHAsoT1YiCf4BvBLcCcJMdcDPwhYX0aMCud9ystLfVWKSlxB+/LDr/4k4vdg4s4QXsnVlVVlesIrRKlvFHK6h6tvFHK6h6tvNlkBRZ7ipqa0V037v6uu9e7+yHg9wSXaZraAByXsD4ibGt7CUMgHL6NXkMgiIgAGV66MbOh7r4pXP0fwLIku70InGBmowkK/GXAf2WUsiXhUAemIRBERI7SYqE3s3nARGCQma0HfghMNLPTCT5AryaYlhszG0ZwuWaqux80s2uBJwgu88xx9+Xt8ldAUNS/BgwuhmdWt9vbiIhETYuF3t0vT9J8T4p9NwJTE9bnA0fdetmeNASCiEhjseoZqyEQRESOFp9CX1EBu3biW7aoZ6yISIJ4FPqwZ6wdqg/W1TNWROSweBR6TQ4uIpJSPAp94iTgbsnbRUS6qHgU+oTJwRvddaPJwUVEYlLow56xRkKVV89YEREgLnPGNvSAvSIPx9QzVkQkQTwKPUB5OfYN8EF74V+rc51GRKTTiMelm5A6TImIHC1WhV5ERI4Wq0JvBu76WC8ikig+hb6iAntvK2zdqiEQREQSxKPQN0wOfqg+uMFSQyCIiBwWj0IfDoEQdJjS5OAiIoniUejDoQ4adZhKaBcR6criUejDoQ7yONT4x1gNgSAi0nKhN7M5ZrbFzJYltP3CzN4ws1fN7CEz65/i2NVmttTMlpjZ4rYM3kjCEAiHGgq9hkAQEQHS+0Q/F5jcpG0BcIq7fxh4E/huM8eXufvp7j4+s4hpKC+H2bOx/LxgFtuSEpg9W0MgiIiQ3pyxz5jZqCZtTyasPg9c3LaxMlBeTt4M8GPy4cXVuU4jItJpmKcxm3ZY6B9x91OSbPu/wP3u/qck294BthN8zv6du89u5j2mA9MBiouLSysrK9P8E464/PKzOOmkbcycubLVx+ZCbW0tRUVFuY6RtijljVJWiFbeKGWFaOXNJmtZWVl1yisn7t7iAowCliVpnwE8RHjCSLJ9ePg4GHgFmJDO+5WWlnomRo92v+CCTRkdmwtVVVW5jtAqUcobpazu0cobpazu0cqbTVZgsaeoqRnfdWNmVwEXAuXhmyQ7iWwIH7eEJ4QzM32/FlVUkLduNb6tRj1jRUQSZFTozWwy8G3g0+5el2Kf3mbWp+E5MAlYlmzfrDVMDn7wQHDXjXrGiogcls7tlfOAfwMnmtl6M7samAX0ARaEt07eHe47zMzmh4cWA8+Z2SvAC8Cj7v54u/wVCT1jUc9YEZFG0rnr5vIkzfek2HcjMDV8/jZwWlbp0hX2gM3j0JH76BPaRUS6slj1jM2nnkOH1DNWRCRRPAp92DO20RAI6hkrIgLEZc7YsAds/ufzqXdNDi4ikigehR6gvJz828F7vAfLVuc6jYhIpxGPSzehvDwaX6MXEZF4Ffr8fKivV6EXEUkUn0JfUUHekmp85271jBURSRCPQh/2jM3fVxdculHPWBGRw+JR6MOesfnUH+kwpZ6xIiJAXAp92AM2n3rqD+Ud1S4i0pXFo9CHPWALOEi9esaKiDQSj0If9oztxgEO1ucHbeoZKyICxKXDVNgDttuXugWXbtQzVkTksHgUeoDycrr9Aw48XwerV+c6jYhIpxGPSzeh7t3VYUpEpKlYFfpu3eDgQRV6EZFEKvQiIjGXVqE3szlmtsXMliW0DTSzBWb2Vvg4IMWxV4b7vGVmV7ZV8KNUVNBt3n0cfP+QhkAQEUmQ7if6ucDkJm03AQvd/QRgYbjeiJkNBH4InAWcCfww1QkhK+EQCN1qa4K7bjQEgojIYWkVend/Bqhp0nwRcG/4/F7gM0kO/RSwwN1r3H07sICjTxjZC4dACO6jD/8kDYEgIgKAuXt6O5qNAh5x91PC9R3u3j98bsD2hvWEY24Eerr7T8L1HwB73f22JK8/HZgOUFxcXFpZWZn+X1FdDcCcxz/GnxaezcKf3441XKovLU3/dTpYbW0tRUVFuY6RtijljVJWiFbeKGWFaOXNJmtZWVm1u49PutHd01qAUcCyhPUdTbZvT3LMjcD3E9Z/ANzY0nuVlpZ6q5SUuIP/lJsc3PfSwx2C9k6sqqoq1xFaJUp5o5TVPVp5o5TVPVp5s8kKLPYUNTWbu27eNbOhAOHjliT7bACOS1gfEba1rXAIhELqANhLLw2BICISyqbQPww03EVzJfCPJPs8AUwyswHhj7CTwra2VV4Os2fTa2AhAHXDPwCzZ2sIBBER0hwCwczmAROBQWa2nuBOmluBB8zsamANcEm473jgGnf/orvXmNmPgRfDl7rZ3Zv+qNs2ysspdGAa1FX9B05ol3cREYmctAq9u1+eYtN5SfZdDHwxYX0OMCejdK1UGHygp66uI95NRCQaYtUztlev4HHv3tzmEBHpTGJV6Av/tQCAuo+ep96xIiKh+BT6igoKb7sZgDp6qXesiEgoPoV+xgx67dsOhLdXgnrHiogQp0K/di1F1AKwmz6N2kVEurL4FPqRIxkYDsezjWMatYuIdGXxKfS33EKfXvXk59VTw8CgTb1jRUTiNWesAX2/8j7bdg/SBOEiIqH4fKIHKC+n70DY9tkvBROEq8iLiMSs0AP9+h1g27ZcpxAR6TxiV+j79lWhFxFJFLtC36fPQWraZ9g0EZFIilehr6ig7/6NbNv4Pl4ySr1iRUSIU6EPJwjv12MP++hJ3dqtGgJBRIQ4FfpwgvC+vYOhK7dyrIZAEBEhToU+HOpgyIBdAKxmVKN2EZGuKj6FPhzqYPigHQCsZGyjdhGRrirjQm9mJ5rZkoRll5l9o8k+E81sZ8I+M7OPnEI4Qfix/XfTnX1BodcQCCIimQ+B4O4rgNMBzCwf2AA8lGTXZ939wkzfJ21hL9j8mhqO523eKjxNE4SLiNB2Y92cB6xy9zVt9HqZKS+HRYsYe+FJrFx7EqjGi4hg7p79i5jNAV5y91lN2icCfwPWAxuBG919eYrXmA5MByguLi6trKzMKEttbS333nsajzwyjPnzn8Uso5fpELW1tRQVFeU6RtqilDdKWSFaeaOUFaKVN5usZWVl1e4+PulGd89qAboD7wHFSbb1BYrC51OBt9J5zdLSUs9UVVWVz5rlDu4bN2b8Mh2iqqoq1xFaJUp5o5TVPVp5o5TVPVp5s8kKLPYUNbUt7rqZQvBp/t0kJ5Fd7l4bPp8PdDOzQW3wns06Yd1CAFYOm6BJwkWky2uLQn85MC/ZBjMbYhZcPDGzM8P3a98hx2pqGPvr6wF4i7GaJFxEurysCr2Z9QYuAB5MaLvGzK4JVy8GlpnZK8CdwGXhV4z2s2EDI99fQQEHeIsTgjb1kBWRLiyru27cfQ8kTtAK7n53wvNZwKymx7Wr/fspoJ4PsZwXOPNIu3rIikgXFZ+esQ26dwfgAhbwHJ9gD4VBu3rIikgXFb9CP3w4FBYyiSfZTw+eYYJ6yIpIlxa/Qj9wIMyezSeOW0tP9vJkn4vVQ1ZEurT4FXqA8nJ6rV3BhEm9ePK4q1XkRaRLi2ehD02aBK+9BuvX5zqJiEjuxL7QAyxYkNscIiK5FOtCf8opMKTfXp689mHIy1MvWRHpktpq9MpOyf5cwaRaeLT+UxwC8hp6yYKu24tIlxHrT/TMmMGk+vlsYxAvc0bQpl6yItLFxLvQr13L+TxFHvVUJA5Or16yItKFxLvQjxxJMVuYxh/5LV9lPcMPt4uIdBXxLvThPLI/4kccIo+bmalesiLS5cS70JeXw+zZjCqBa/gdc/gCb/7vefohVkS6lHgXegiK+urVzNh8HT17FzBz8adznUhEpEPFv9CHiovhG9+A+++Hl1/OdRoRkY7TZQo9wI03woABurtSRLqWLlXo+/eHm26Cxx6DZ5/NdRoRkY6RdaE3s9VmttTMlpjZ4iTbzczuNLOVZvaqmY3L9j2zce21MLR/Hd+94EXcNCyCiMRfW32iL3P30919fJJtU4ATwmU6cFcbvWdGCh+qYOaem/jXvo8wnymaPFxEYq8jLt1cBNzngeeB/mY2tAPeN7kZM7j6wF2MYSXf4hfsoJ+GRRCRWDN3z+4FzN4BtgMO/M7dZzfZ/ghwq7s/F64vBL7j7oub7Ded4BM/xcXFpZWVlRnlqa2tpaioKPUO1dUALH6zhO/d8xlGDdnGbV/+K30L34fS0ozeM1MtZu1kopQ3SlkhWnmjlBWilTebrGVlZdUprqqAu2e1AMPDx8HAK8CEJtsfAT6RsL4QGN/ca5aWlnqmqqqqmt+hpMQd3MEfZYr3YK+fzku+dcTpGb9nplrM2slEKW+UsrpHK2+UsrpHK282WYHFnqKmZn3pxt03hI9bgIeAM5vssgE4LmF9RNiWG+GwCABTeYx/cBFv8EHOtafZsiVnqURE2k1Whd7MeptZn4bnwCRgWZPdHgauCO++ORvY6e6bsnnfrITDIlBSAmZ8qmQFj9z0L1a+N4CyMti8OWfJRETaRbYTjxQDD5lZw2v92d0fN7NrANz9bmA+MBVYCdQBn8/yPbNXXt5ovJvzgPmfggsvhIkT4emnYdiwnKUTEWlTWRV6d38bOC1J+90Jzx34Wjbv0xEmTgw6Uk2deqTYjxiR61QiItnrUj1jW/LJT8ITTwSXb845R/OTiEg8qNA38bGPwYIFsG1bUOxX3/H3oPesJhcXkYhSoU/irLPgqadg59Z9nPO/xrFqTX5wQ6Z60YpIBKnQpzB+PCzs+1n2eCHn8E9e5vRgg3rRikjEqNA344zNj/E053KAbozjZS7hfpZzsi7ei0ikqNA3Z+RIPsxS3uCDfJ8f8xhTOJWllPd6kBUrch1ORCQ9KvTNCXvRDmAHP2Ym7zCabxf8ir/XX8jJJ8NVV8GqVbkOKSLSPBX65jTpRTuopIhb5w7hnbUFh6clPPFE+OIXg99pRUQ6IxX6loSTi3PoUPBYXs7gwfDLX8Lbb8NXvwp//COccAJ85Suwfn2uA4uINKZCn4WhQ+HOO4PLN1dfDffcA2PGwPXXw6bcjeYjItKICn0bGDEC7roL3nwTrrgCfvtbOP54uOEGNCKmiOScCn0bGjUKfv97WLECLr0U7rgDRo8OJiR/771cpxORrkqFvh2MGQNz58Jrr8FFF8HPfx4U/B/8ALbP/suRIRWWLlUvWxFpdyr07ejEE+HPfw7q+ZQp8JOfwOgvX8DNa65gp/eB/fs1pIKItDsV+g7woQ/BAw/AkqFTKKOKH3IzQ9jMjb+7mJ/VXUv1jfOor891ShGJq2wnHpFWOG3zEzzE41Qzjj8yjYd3l3MTP4PNMOBYOPdcOO88OP98GDsWgvlcRESyo0/0HWnkSABKeYk7+CZzbryPTQyhYtD1fOYz8MILwX35H/hAcBn/C18ILv28+25uY4tItGVc6M3sODOrMrPXzGy5mX09yT4TzWynmS0Jl5nZxY24hInJGwwp3M1/3XEWc+YEvWvffDO4PfMjH4G//z3orzVkCJx6Knzzm/Doo7B7d47yi0gkZXPp5iBwg7u/FE4QXm1mC9z9tSb7PevuF2bxPvHRME/tjBnBCJjduwdDLITtZkEP24ZetvX1sGRJMDb+U0/B3XcHt2wWFARj5jdc5jnrrOClRESSyfgTvbtvcveXwue7gdeB4W0VLLYSh1Q49dRGk5Q3lZ8PpaXwne8Es15t3w4LF8K3vw0HDgR38UyYAAMHBnPd3n47vPJK8NIiIg0smLs7yxcxGwU8A5zi7rsS2icCfwPWAxuBG919eYrXmA5MByguLi6trKzMKEttbS1FRUUZHdvRss1aW1vAkiX9qa4eQHX1ANatCy4L9e+/n3HjtjNu3A5KS7czZMj7nSJvR4pSVohW3ihlhWjlzSZrWVlZtbuPT7rR3bNagCKgGvhskm19gaLw+VTgrXRes7S01DNVVVWV8bEdra2zrlvnPneu+7Rp7kOHugfzH7qPGeM+fbr7Aw+4b92a+et35f+27S1KeaOU1T1aebPJCiz2FDU1q7tuzKwbwSf2Cnd/MMlJZJe714bP5wPdzGxQNu8pqY0YAVdeCffdBxs2BD1z77wzuI+/shIuuQQGD4Zx44LLP088EcyM2EhFhSZDF4mZjH+MNTMD7gFed/fbU+wzBHjX3d3MziT4TWBbpu8p6TODk04Kluuug4MHYfHi4Br/U0/Br38Nv/hF8CPuRz8a/Kh7fv3jjP/ZVyjYG97W0zAZOjT7W4KIdG7Z3HXzcWAasNTMloRt3wNGArj73cDFwFfM7CCwF7gs/IohHaygAM4+O1hmzAg+yT/3XFD0Fy6EmTPhBz6ZvqxjAs9wCssYwyrG1K1izHd+w4jLVehFoirjQu/uzwHN9t1091nArEzfQ9pPYSFMmhQsEIyuWXXsJSzkXBYxkceZzEG6BRs3QPdeUFx8JqeeGgzaNnZs8DhmTDBgW48euftbRKR5GgJBABg0CD5X8gKfW/MXAA6SzzqOYxVjWDXwTFZd/VOef34PGzYU8swzUFt75Fiz4PeBhsLfdOnfP0d/lIgAKvSS6JZbgmvydXUUUM9oVjO6cAvn3/l5KIdFi5YzceJE3GHr1mBmrabLI48cPWTDwIGpTwJDhwa/+4pI+1GhlyOa9twdOTIo/k1+iDUL7t4ZPDj4Ibep2tpgPt2G4r9yZfD4n//AX/5Co5E6e/YMZuNqKPyJl4RKStTjV6QtqNBLY+XlWd9hU1QEH/5wsDR14EBwM0+ybwNPPQV79x7ZNy8vONek+jbQp09WMUW6DBV66VDdugWf2seOPXqbO2zenPwk8OCDR0/HeOyxqU8CurdL5AgVeuk0zIJr9kOHwic+cfT2nTuTXxJ69tlgOOfE4t6z5yf5wAeSnwRGjgxuNxXpKvTPXSKjXz8444xgaWrfvmCsuIaTwD//uYl9+0bwxhswf36wvUFBQXD9P9lJ4PjjoXfvDvuTRDqECr3EQo8ewRy9J54YrJ966komThwBBKN5btyY/JLQiy8Go4ImGjIk9SWhQYOazPxVUdHij9ciuaZCL7GXlxfc5z9iBJxzztHbt28/+nLQqlVBj+H77mu8b9++CYX//eWMefL/cfz+MQymDwPX1DDwS9fTC1TspVNRoZcub8AAGD8+WJrauxfeeefobwKvvgr/ePMEDvCbJgdAz2nvc8x3gv4DTZdjjkne/v77ebhrnmBpHyr0Is3o1QtOPjlYmqq3QtYznHcYzXsMooaBweLHsO1T36KmBmpq4K23gsdt2xr/VtDYBHr0SO/E0LStd2+dIKR5KvQiGcovGUHJmjWUsLbxhpISuOdbSY+pq+PwCSBxefHFVfTvP6ZR29tvByOO1tQ07l/QVLduzX9bSNXep49OEF2FCr1IphKGjDissDBoT6GwMFhGjGjcPnbsOiZOHJPyuL17g98SGr4ZJDtZNLSvWQMvvxw837MndfyCgvRPCont6qMQPSr0IplKc8iIttCrV7AMG9a64/bta/6kkLhs2BD89lBT03jQuqby8s5p1YmhYenXT+Ma5YoKvUg22mDIiPbUo8eRTmitsX//kW8QTU8ML7+8lj59Sg63b9oEy5cH23btSv2aeXnBD9+t/RbRrx/k52f336GrU6EXkaN07w7FxcHS1KJF7zBxYknS4w4caHyCaO5bxNatsGJF0L5zZ+osZsFQ1639FtG/v3pAN9B/BhFpM926HRnZtDUOHoQdO1q+vLRtW7A03Mm0Y0fzvxn07w+FhWcxbFj63yIGDIjfCSKrP8fMJgO/BvKBP7j7rU229wDuA0oJ5oq91N1XZ/OeIhI/BQVBr+NBg1p3XH198G2guR+oX399F9269aKmJugTUVMTfOs4dCj16/bt2/rbXAcMyGJY7YYe1tddB1dd1ea/9WQzOXg+8BvgAmA98KKZPezuryXsdjWw3d3HmtllwM+AS7MJLCLSID//SKFNZdGi15k4sfE1qEOHghNES98gGtrXrj2y3twJoqio9be5DnxiHj2+lnD31po1wd1c0GbFPptP9GcCK939bQAzqwQuAhIL/UXAj8LnfwVmmZlpgnARyaWGH4YHDAiGs0jXoUOwe3d6t7nW1MDSpUeeHzyY6lUvpzf/nYHUMOA3ebzCjUHRnzGjzQq9ZVpzzexiYLK7fzFcnwac5e7XJuyzLNxnfbi+KtznvSSvNx2YDlBcXFxaWVmZUa7a2lqKiooyOrajRSkrRCtvlLJCtPJGKSt0jrzuUFeXz+7d3di1q+Dw465d3dj9xhZ21fVkd11PDvXtxXen/v3IgaWlab9HWVlZtbsnGcgDcPeMFuBiguvyDevTgFlN9lkGjEhYXwUMaum1S0tLPVNVVVUZH9vRopTVPVp5o5TVPVp5o5TVPQJ5S0rcg3OBV9122+HnXlLSqpcBFnuKmppN94UNwHEJ6yPCtqT7mFkB0I/gR1kREYHgh9fCwsZtLfSwbq1sCv2LwAlmNtrMugOXAQ832edh4Mrw+cXA0+GZR0REILgOP3t2MEYSBI+zZ3eOu27c/aCZXQs8QXB75Rx3X25mNxN8hXgYuAf4o5mtBGoITgYiIpKooYf1okXBVGltLKv76N19PjC/SdvMhOfvA5/L5j1ERCQ7GmJIRCTmVOhFRGJOhV5EJOZU6EVEYi7jnrHtycy2AmsyPHwQcFTP204qSlkhWnmjlBWilTdKWSFaebPJWuLuxybb0CkLfTbMbLGn6gbcyUQpK0Qrb5SyQrTyRikrRCtve2XVpRsRkZhToRcRibk4FvrZuQ7QClHKCtHKG6WsEK28UcoK0crbLlljd41eREQai+MnehERSaBCLyISc7Ep9GY22cxWmNlKM7sp13maY2bHmVmVmb1mZsvN7Ou5ztQSM8s3s5fN7JFcZ2mJmfU3s7+a2Rtm9rqZfTTXmVIxs2+G/waWmdk8M+uZ60yJzGyOmW0JZ4traBtoZgvM7K3wcUAuMzZIkfUX4b+DV83sITPrn8uMiZLlTdh2g5m5mbVyuvTkYlHoEyYqnwKcDFxuZifnNlWzDgI3uPvJwNnA1zp5XoCvA6/nOkSafg087u4fBE6jk+Y2s+HA9cB4dz+FYLjvzjaU91xgcpO2m4CF7n4CsDBc7wzmcnTWBcAp7v5h4E3gux0dqhlzOTovZnYcMAlY21ZvFItCT8JE5e6+H2iYqLxTcvdN7sWvFVoAAAKeSURBVP5S+Hw3QSEanttUqZnZCOC/AX/IdZaWmFk/YALBXAi4+35335HbVM0qAHqFM7AVAhtznKcRd3+GYC6JRBcB94bP7wU+06GhUkiW1d2fdPeGabmfJ5gJr1NI8d8W4FfAt4E2u1MmLoV+OLAuYX09nbhwJjKzUcAZwH9ym6RZdxD8wzuU6yBpGA1sBf5PeKnpD2bWO9ehknH3DcBtBJ/cNgE73f3J3KZKS7G7bwqfbwaKcxmmFb4APJbrEM0xs4uADe7+Slu+blwKfSSZWRHwN+Ab7r4r13mSMbMLgS3uXp3rLGkqAMYBd7n7GcAeOs+lhUbCa9sXEZychgG9zex/5jZV64RTg3b6e7TNbAbBJdOKXGdJxcwKge8BM1vat7XiUujTmai8UzGzbgRFvsLdH8x1nmZ8HPi0ma0muCR2rpn9KbeRmrUeWO/uDd+Q/kpQ+Duj84F33H2rux8AHgQ+luNM6XjXzIYChI9bcpynWWZ2FXAhUN7J56weQ3DSfyX8/20E8JKZDcn2heNS6NOZqLzTMDMjuIb8urvfnus8zXH377r7CHcfRfDf9Wl377SfOt19M7DOzE4Mm84DXsthpOasBc42s8Lw38R5dNIfjpt4GLgyfH4l8I8cZmmWmU0muOz4aXevy3We5rj7Uncf7O6jwv/f1gPjwn/TWYlFoQ9/bGmYqPx14AF3X57bVM36ODCN4NPxknCZmutQMXIdUGFmrwKnAz/NcZ6kwm8dfwVeApYS/P/Yqbrrm9k84N/AiWa23syuBm4FLjCztwi+ldyay4wNUmSdBfQBFoT/n92d05AJUuRtn/fq3N9kREQkW7H4RC8iIqmp0IuIxJwKvYhIzKnQi4jEnAq9iEjMqdCLiMScCr2ISMz9f2Sx6VlR0onmAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.3\n",
        "\n",
        "Repita o exercício 2 mas usando agora o calculando o gradiente usando o método backward() do pytorch. Confira se o primeiro valor do gradiente está de acordo com os valores anteriores. Execute essa próxima célula duas vezes. Os valores devem ser iguais."
      ],
      "metadata": {
        "id": "TeUU389rbLD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "iteracoes = 20\n",
        "\n",
        "x = torch.arange(0, 4).float()\n",
        "y = torch.arange(0, 8, 2).float()\n",
        "w = torch.ones(1, requires_grad=True)\n",
        "xVet = []\n",
        "yVet = []\n",
        "for i in range(iteracoes):\n",
        "    print('i =', i)\n",
        "    yVet.append(i)\n",
        "    J = J_func(w, x, y)\n",
        "    xVet.append(J.detach( ))\n",
        "    print('J=', J.detach( ))\n",
        "    if w.grad: w.grad.zero_()\n",
        "    J.backward()\n",
        "    grad = w.grad\n",
        "    print('grad =',grad.item())\n",
        "    w = w - learning_rate* grad.item()\n",
        "    w.retain_grad()\n",
        "    print('w =', w.detach( ))\n",
        "\n",
        "# Plote aqui a loss pela iteração\n",
        "plt.plot(xVet,yVet,color=\"blue\")\n",
        "plt.scatter(xVet,yVet,color=\"red\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e0IBUSQSbNbG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7382aaa0-df90-4974-d39d-22f325fa41bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i = 0\n",
            "J= tensor(14.)\n",
            "grad = -28.0\n",
            "w = tensor([1.2800])\n",
            "i = 1\n",
            "J= tensor(7.2576)\n",
            "grad = -20.160001754760742\n",
            "w = tensor([1.4816])\n",
            "i = 2\n",
            "J= tensor(3.7623)\n",
            "grad = -14.51519775390625\n",
            "w = tensor([1.6268])\n",
            "i = 3\n",
            "J= tensor(1.9504)\n",
            "grad = -10.450942993164062\n",
            "w = tensor([1.7313])\n",
            "i = 4\n",
            "J= tensor(1.0111)\n",
            "grad = -7.52467679977417\n",
            "w = tensor([1.8065])\n",
            "i = 5\n",
            "J= tensor(0.5241)\n",
            "grad = -5.417766094207764\n",
            "w = tensor([1.8607])\n",
            "i = 6\n",
            "J= tensor(0.2717)\n",
            "grad = -3.9007928371429443\n",
            "w = tensor([1.8997])\n",
            "i = 7\n",
            "J= tensor(0.1409)\n",
            "grad = -2.808573007583618\n",
            "w = tensor([1.9278])\n",
            "i = 8\n",
            "J= tensor(0.0730)\n",
            "grad = -2.0221731662750244\n",
            "w = tensor([1.9480])\n",
            "i = 9\n",
            "J= tensor(0.0379)\n",
            "grad = -1.455965280532837\n",
            "w = tensor([1.9626])\n",
            "i = 10\n",
            "J= tensor(0.0196)\n",
            "grad = -1.0482935905456543\n",
            "w = tensor([1.9730])\n",
            "i = 11\n",
            "J= tensor(0.0102)\n",
            "grad = -0.7547743320465088\n",
            "w = tensor([1.9806])\n",
            "i = 12\n",
            "J= tensor(0.0053)\n",
            "grad = -0.5434384346008301\n",
            "w = tensor([1.9860])\n",
            "i = 13\n",
            "J= tensor(0.0027)\n",
            "grad = -0.39127326011657715\n",
            "w = tensor([1.9899])\n",
            "i = 14\n",
            "J= tensor(0.0014)\n",
            "grad = -0.281719446182251\n",
            "w = tensor([1.9928])\n",
            "i = 15\n",
            "J= tensor(0.0007)\n",
            "grad = -0.20283913612365723\n",
            "w = tensor([1.9948])\n",
            "i = 16\n",
            "J= tensor(0.0004)\n",
            "grad = -0.14604616165161133\n",
            "w = tensor([1.9962])\n",
            "i = 17\n",
            "J= tensor(0.0002)\n",
            "grad = -0.10515189170837402\n",
            "w = tensor([1.9973])\n",
            "i = 18\n",
            "J= tensor(0.0001)\n",
            "grad = -0.07571077346801758\n",
            "w = tensor([1.9981])\n",
            "i = 19\n",
            "J= tensor(5.3059e-05)\n",
            "grad = -0.054509878158569336\n",
            "w = tensor([1.9986])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.4\n",
        "\n",
        "Quais são as restrições na escolha dos valores de $\\Delta w$ no cálculo do gradiente por diferenças finitas?"
      ],
      "metadata": {
        "id": "4_LZWjqqbSbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R: Caso delta w seja um valor de grandeza muito pequeno o cálculo do gradiente vai resultar em 0, o mesmo acontece se for subindo o seu valor.   "
      ],
      "metadata": {
        "id": "VQ3f7KCsH_JP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.5\n",
        "\n",
        "Até agora trabalhamos com $w$ contendo apenas um parâmetro. Suponha agora que $w$ seja uma matriz com $N$ parâmetros e que o custo para executar $(x_i w - y_i)^2$ seja $O(N)$.\n",
        "> a) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método das diferencas finitas?\n",
        ">\n",
        "> b) Qual é o custo computacional para fazer uma única atualização (um passo de gradiente) dos parâmetros de $w$ usando o método do backpropagation?"
      ],
      "metadata": {
        "id": "7MLdWhXEbemx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A: Por w ser uma matriz com N parâmetros é necessário utilizar todos os elementos de w para calcular a função j, com isso seu custo computacional seria $O(N)N$\n",
        "\n",
        "B:Como o backpropagation calcula o gradiente da função perda para cada peso pela regra da cadeia o custo computacional é mais otmizado, ficando $O(N)$"
      ],
      "metadata": {
        "id": "ur1dHYSwMND1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercício 3.6\n",
        "\n",
        "Qual o custo (entropia cruzada) esperado para um exemplo (uma amostra) no começo do treinamento de um classificador inicializado aleatoriamente?\n",
        "\n",
        "A equação da entropia cruzada é:\n",
        "$$L = - \\sum_{j=0}^{K-1} y_j \\log p_j, $$\n",
        "Onde:\n",
        "\n",
        "- K é o número de classes;\n",
        "\n",
        "- $y_j=1$ se $j$ é a classe do exemplo (ground-truth), 0 caso contrário. Ou seja, $y$ é um vetor one-hot;\n",
        "\n",
        "- $p_j$ é a probabilidade predita pelo modelo para a classe $j$.\n",
        "\n",
        "A resposta tem que ser em função de uma ou mais das seguintes variáveis:\n",
        "\n",
        "- K = número de classes\n",
        "\n",
        "- B = batch size"
      ],
      "metadata": {
        "id": "-81LppH5bmVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Resposta**:\n",
        "$$sendo:  1/K = p_j $$ \n",
        "substituindo na fórmula fica: $$L = -  \\log(1/K) $$"
      ],
      "metadata": {
        "id": "_GHo57YCbrfO"
      }
    }
  ]
}